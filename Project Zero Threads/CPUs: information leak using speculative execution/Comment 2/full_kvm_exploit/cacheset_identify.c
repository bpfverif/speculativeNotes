#include "common.h"

// define SINGLE_MERGEDCORES_SET for faster debug
//#define SINGLE_MERGEDCORES_SET


unsigned long get_physaddr(unsigned long vaddr) {
/*
  int pagemap_fd = open("/proc/self/pagemap", O_RDONLY);
  if (pagemap_fd == -1)
    err(1, "open pagemap");
  uint64_t pm_val;
  if (pread(pagemap_fd, &pm_val, 8, vaddr / 4096 * 8) != 8)
    err(1, "read pagemap");
  close(pagemap_fd);
  if ((pm_val & (1ULL<<63)) != 0) {
    unsigned long page_physaddr = (pm_val & 0x7fffffffffffff)*0x1000;
    return page_physaddr | (vaddr & 0xfffUL);
  }
  return (unsigned long)-1L;
*/

  /* cheat hypercall */
  unsigned long physaddr = 0;
  asm volatile(
    "mov $0x13370001, %%rax\n\t"
    "vmcall"
  : "=a"(physaddr) : "D"(vaddr) : "cc");
  return physaddr;
}


// ================ BINOMIAL ================
double binomial_coefficient(uint64_t n, uint64_t k) {
  assert(k <= n);
  if (k * 2 > n)
    k = n - k;
  double res = 1;
  for (uint64_t i = 0; i < k; i++)
    res *= ((double)(n - i)) / ((double)(k - i));
  return res;
}
double binomial_probability(double k, double n, double p) {
  return binomial_coefficient(n, k) * pow(p, k) * pow(1-p, n-k);
}
double binomial_probability_range(int k1, int k2, double n, double p) {
  double sum = 0;
  for (int k=k1; k<=k2; k++) {
    sum += binomial_probability(k, n, p);
  }
  return sum;
}
double binomial_probability_not_range(int k1, int k2, double n, double p) {
  return 1 - binomial_probability_range(k1, k2, n, p);
}
// ==========================================


struct cacheline *cachelines;
unsigned int next_set_id = 1;

void select_random_noset_lines(struct cacheline **result, int count) {
  static struct cacheline *candidates[NPAGES];
  int candidates_count = 0;
  //printf("%s select_random_noset_lines entry\n", cur_time());
  for (int i=0; i<NPAGES; i++) {
    struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
    if (line->set_id == 0) {
      candidates[candidates_count] = line;
      candidates_count++;
    }
  }
  assert(candidates_count >= count);

  for (int i=0; i<count; i++) {
    struct cacheline **selected_ptr = candidates + (rand() % candidates_count);
    *(result++) = *selected_ptr;

    // swap the candidate we selected to the end, then cut off the end
    candidates_count--;
    *selected_ptr = candidates[candidates_count];
  }
  //printf("%s select_random_noset_lines exit\n", cur_time());
}

void dump_all(void) {
  for (int i=0; i<NPAGES; i++) {
    struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
    unsigned long paddr = get_physaddr((unsigned long)line);
    printf("[DUMPALL] paddr=0x%010lx mergedcores_pgaligned_set=0x%lx set_id=%u [CHEAT]\n",
        paddr, (paddr / PAGE_SIZE) & (SETS_PER_IN_PAGE_OFFSET_MERGEDCORES-1), line->set_id);
  }
}

int count_unsorted_lines(void) {
  int count = 0;
  for (int i=0; i<NPAGES; i++) {
    struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
    if (line->set_id == 0) {
      count++;
    }
  }
  return count;
}

void linkify_set(struct cacheline **set, int count) {
  assert(count);
  for (int i=0; i<count; i++) {
    set[i]->next = (i == count-1 ? set[0] : set[i+1]);
  }
}

int delinkify_set(struct cacheline **set, struct cacheline *head) {
  if (head == NULL) return 0;
  struct cacheline *line = head;
  int i = 0;
  do {
    set[i] = line;
    i++;
    line = line->next;
  } while (line != head);
  return i;
}

void measure_set(struct cacheline *head, int iters) {
  struct cacheline *cur;

  if (head == NULL) return;

  cur = head;
  do {
    cur->hot_count = 0;
    cur = cur->next;
  } while (cur != head);

  for (int i=0; i<iters; i++) {
    do_flushing_and_time(head, NULL);
    cur = head;
    do {
      if (is_hot_diff(cur->access_time)) {
        cur->hot_count++;
      }
      cur = cur->next;
    } while (cur != head);
  }
}

void clean_hot_lines(struct cacheline **head) {
  if (*head == NULL) return;

  struct cacheline *orig_head = *head;
  struct cacheline **curp = head;
  int hot_lines = 0;
  while (1) {
    if ((*curp)->next == orig_head) {
      (*curp)->next = *head;
    }
    if ((*curp)->hot_count >= 5) {
      hot_lines++;
      if ((*curp)->next == *curp) {
        *head = NULL;
        goto out;
      }
      *curp = ((*curp)->next);
    } else {
      curp = &(*curp)->next;
      if (*curp == *head) {
        break;
      }
    }
  };
out:
  if (hot_lines) {
    printf("%s got rid of %d hot lines\n", cur_time(), hot_lines);
  }
}

int count_cold(struct cacheline *head) {
  if (head == NULL) return 0;

  int res = 0;
  struct cacheline *cur = head;
  do {
    if (cur->hot_count < 5) {
      res++;
    }
    cur = cur->next;
  } while (cur != head);
  return res;
}

int set_size(struct cacheline *head) {
  if (head == NULL) return 0;

  int res = 0;
  struct cacheline *cur = head;
  do {
    res++;
    cur = cur->next;
  } while (cur != head);
  return res;
}

struct cacheline *get_list_element(struct cacheline *line, int i) {
  while (i--) line = line->next;
  return line;
}

void dump_set(struct cacheline *head) {
  if (head == NULL) return;

  struct cacheline *cur = head;
  do {
    unsigned long paddr = get_physaddr((unsigned long)cur);
    printf("%s   element at paddr 0x%010lx; mergedcores_pgaligned_set=0x%lx hot_count=%d [CHEAT]\n",
        cur_time(), paddr, (paddr / PAGE_SIZE) & (SETS_PER_IN_PAGE_OFFSET_MERGEDCORES-1), cur->hot_count);
    cur = cur->next;
  } while (cur != head);
}

int find_and_remove_permahot_highprecision(struct cacheline **array, int size) {
  for (int i=0; i<size; i++) {
    array[i]->hot_count_l2 = 0;
  }

  linkify_set(array, size);
  struct cacheline *head = array[0];

  /* main measurement */
  struct cacheline *subhead = head;
  do {
    measure_set(subhead, 10);
    {
      struct cacheline *line = subhead;
      do {
        if (line->hot_count >= 5)
          line->hot_count_l2++;
        line = line->next;
      } while (line != subhead);
    }
    subhead = subhead->next;
  } while (subhead != head);

  /* collect lines that were cold in at least some positions */
  struct cacheline **array_outptr = array;
  for (int i=0; i<size; i++) {
    if (array[i]->hot_count_l2 < size) {
      *(array_outptr++) = array[i];
    }
  }
  return array_outptr - array;
}

#define LOW_PRECISION_ITERS 4
int find_and_remove_permahot_lowprecision(struct cacheline **array, int size) {
  for (int i=0; i<size; i++) {
    array[i]->hot_count_l2 = 0;
  }

  linkify_set(array, size);
  struct cacheline *head = array[0];

  /* main measurement */
  struct cacheline *subhead = head;
  //printf("===========================\n");
  for (int i=0; i<LOW_PRECISION_ITERS; i++) {
    //printf("---------------------------\n");
    measure_set(subhead, 10);
    //dump_set(subhead);
    {
      struct cacheline *line = subhead;
      do {
        if (line->hot_count >= 5)
          line->hot_count_l2++;
        line = line->next;
      } while (line != subhead);
    }
    subhead = get_list_element(subhead, size/LOW_PRECISION_ITERS);
  }

  /* collect lines that were cold in at least some positions */
  struct cacheline **array_outptr = array;
  for (int i=0; i<size; i++) {
    if (array[i]->hot_count_l2 < LOW_PRECISION_ITERS) {
      *(array_outptr++) = array[i];
    }
  }
  return array_outptr - array;
}

int add_lines_to_set(struct cacheline **test_lines_, int initial_set_size) {
  static struct cacheline *test_lines[EVICTION_SET_SIZE];
  static struct cacheline *unused_lines[NPAGES];
  int unused_lines_count = 0;
  int added_lines = 0;
  int eviction_set_size = (initial_set_size > EVICTION_SET_SIZE) ? EVICTION_SET_SIZE : initial_set_size;

  memcpy(test_lines, test_lines_, eviction_set_size * sizeof(test_lines[0]));

  linkify_set(test_lines, eviction_set_size);

  for (int i=0; i<NPAGES; i++) {
    struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
    if (line->set_id == 0) {
      unused_lines[unused_lines_count] = line;
      unused_lines_count++;
    }
  }

  int progress = 0, last_progress = 0;
  for (int i=0; i<unused_lines_count; ) {
    progress = 100*i/unused_lines_count;
    if (progress != last_progress) {
      printf("\r%s testing for unmapped lines in set: %d%%", cur_time(), progress);
      last_progress = progress;
    }

    /* fastpath: try to batch-eliminate a bunch at a time. bail out if unsure. */
    #define BATCH_FACTOR_BIG 16
    if (i + BATCH_FACTOR_BIG <= unused_lines_count) {
      linkify_set(unused_lines+i, BATCH_FACTOR_BIG);
      for (int j=0; j<4; j++) {
        do_flushing_and_time(test_lines[0], unused_lines[i]);
        for (int k=0; k<BATCH_FACTOR_BIG; k++) {
          if (!is_hot_diff(unused_lines[i+k]->access_time)) {
            goto slowpath_smallbatch;
          }
        }
      }
      i += BATCH_FACTOR_BIG;
      continue;
    }

slowpath_smallbatch:;
    #define BATCH_FACTOR_SMALL 4
    if (i + BATCH_FACTOR_SMALL <= unused_lines_count) {
      linkify_set(unused_lines+i, BATCH_FACTOR_SMALL);
      for (int j=0; j<4; j++) {
        do_flushing_and_time(test_lines[0], unused_lines[i]);
        for (int k=0; k<BATCH_FACTOR_SMALL; k++) {
          if (!is_hot_diff(unused_lines[i+k]->access_time)) {
            goto slowpath_nobatch;
          }
        }
      }
      i += BATCH_FACTOR_SMALL;
      continue;
    }

slowpath_nobatch:;
    linkify_set(unused_lines+i, 1);
    int hot_count = 0;
    for (int j=0; j<10; j++) {
      do_flushing_and_time(test_lines[0], unused_lines[i]);
      if (is_hot_diff(unused_lines[i]->access_time))
        hot_count++;
      if (j == 3) {
        if (hot_count == 0) goto found_line;
        if (hot_count == 4) goto try_next_unused;
      }
    }
    if (hot_count < 5) {
found_line:;
      unused_lines[i]->set_id = next_set_id;
      added_lines++;
      if (eviction_set_size < EVICTION_SET_SIZE) {
        test_lines[eviction_set_size] = unused_lines[i];
        eviction_set_size++;
        linkify_set(test_lines, eviction_set_size);
      }
    }
try_next_unused:;
    i++;
  }
  printf("\n");

  return added_lines;
}

/*
 * Calculate the number of cachelines that should be sampled for the next attempt to find a cacheset.
 * Approximates sampling from a large set as sampling with independent draws.
 * The goal is to get, on average, one eviction set per `next_attempt_lines()` randomly sampled lines.
 * Therefore, the probability of getting an eviction set for a specific set should be 1/sets_remaining
 * (so that the probabilities sum up to 1).
 */
int next_attempt_lines(void) {
  if (SETS_PER_IN_PAGE_OFFSET - (next_set_id-1) == 1)
    return CACHE_ASSOCIATIVITY + 5;
  double sets_remaining = SETS_PER_IN_PAGE_OFFSET - (next_set_id-1);
  double p = 1.0 / sets_remaining;
  for (int n = CACHE_ASSOCIATIVITY; n < NPAGES; n++) {
    if (binomial_probability_not_range(0, CACHE_ASSOCIATIVITY, n, p) >= p) {
      return n;
    }
  }
  errx(1, "internal error: next_attempt_lines; sets_remaining=%u; maxprob=%f",
    SETS_PER_IN_PAGE_OFFSET - (next_set_id-1),
    binomial_probability_not_range(0, CACHE_ASSOCIATIVITY, NPAGES-1, p)
  );
}

time_t last_success_time;

void find_new_set(void) {
  int attempt_loops = 0;
  int attempt_lines = next_attempt_lines();
  printf("%s attempt_lines=%d\n", cur_time(), attempt_lines);
full_retry:
  attempt_loops++;
  if (attempt_loops % 4 == 0 && attempt_lines < count_unsorted_lines()) attempt_lines++;
  struct cacheline *test_lines[attempt_lines];
  if (last_success_time != 0 && last_success_time + 60*5 < time(NULL)) {
    printf("%s giving up\n", cur_time());
    return;
  }
  select_random_noset_lines(test_lines, attempt_lines);

  int reduced_set_size = attempt_lines;
  while (reduced_set_size >= 2*(CACHE_ASSOCIATIVITY-4)) {
    int last_reduced_set_size = reduced_set_size;
    reduced_set_size = find_and_remove_permahot_lowprecision(test_lines, reduced_set_size);
    if (reduced_set_size != last_reduced_set_size) {
      //printf("sloppy reduction to %d (-%d)\n", reduced_set_size, last_reduced_set_size - reduced_set_size);
    } else {
      //printf("got stuck, cutting off an element\n");
      reduced_set_size--;
    }
  };
  //printf("last sloopy reduction down to %d\n", reduced_set_size);
  if (reduced_set_size == 0) {
    //printf("%s find_new_set() fail\n", cur_time());
    goto full_retry;
  }

  reduced_set_size = find_and_remove_permahot_highprecision(test_lines, reduced_set_size);
  //printf("%s fine reduction down to %d\n", cur_time(), reduced_set_size);
  if (reduced_set_size == 0) {
    //printf("%s find_new_set() fail\n", cur_time());
    goto full_retry;
  }

  reduced_set_size = find_and_remove_permahot_highprecision(test_lines, reduced_set_size);
  //printf("%s fine reduction down to %d\n", cur_time(), reduced_set_size);
  if (reduced_set_size == 0 || reduced_set_size < CACHE_ASSOCIATIVITY) {
    //printf("%s find_new_set() fail\n", cur_time());
    goto full_retry;
  }

  //printf("%s find_new_set() success:\n", cur_time());
  last_success_time = time(NULL);
  linkify_set(test_lines, reduced_set_size);
  //dump_set(test_lines[0]);

  for (int i=0; i<reduced_set_size; i++) {
    test_lines[i]->set_id = next_set_id;
  }

  // now add other lines to the set
  int full_set_size = reduced_set_size;
  full_set_size += add_lines_to_set(test_lines, reduced_set_size);

  printf("%s found set: id=%d, size=%d (%d%% of expected) after %d loops\n", cur_time(), next_set_id, full_set_size, 100*SETS_PER_IN_PAGE_OFFSET*full_set_size/NPAGES, attempt_loops);

  if (100*SETS_PER_IN_PAGE_OFFSET*full_set_size/NPAGES < 60) {
    static int suspiciously_small_sets = 0;
    suspiciously_small_sets++;
    if (suspiciously_small_sets < 10) {
      printf("%s WARNING: set is suspiciously small - rolling back and retrying!\n", cur_time());
      for (int i=0; i<NPAGES; i++) {
        struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
        if (line->set_id == next_set_id)
          line->set_id = 0;
      }
      attempt_loops = 0;
      goto full_retry;
    } else {
      printf("%s WARNING: set is suspiciously small, but that already happened to often - ignoring!\n", cur_time());
    }
  }

  next_set_id++;
}

int main(void) {
  common_init();
  printf("%s === starting cacheset_identify ===\n", cur_time());
  if (sizeof(struct cacheline) != LINE_SIZE)
    errx(1, "struct cacheline wrong size");
  int cachelines_fd = open("/dev/shm/cachelines", O_RDWR|O_EXCL|O_CREAT, 0666);
  if (cachelines_fd == -1)
    err(1, "open cachelines files");
  if (ftruncate(cachelines_fd, NPAGES*PAGE_SIZE))
    err(1, "ftruncate");
  //|MAP_HUGETLB
  cachelines = mmap(NULL, NPAGES*PAGE_SIZE, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, cachelines_fd, 0);
  if (cachelines == MAP_FAILED)
    err(1, "mmap");
  madvise(cachelines, NPAGES*PAGE_SIZE, MADV_NOHUGEPAGE);
  hot_cold_init();

  /* avoid same-page merging and merging with the zeropage */
  for (int i=0; i<NPAGES; i++) {
    struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
    line->uniq = i + 1;
  }

  int n_sets_to_find = SETS_PER_IN_PAGE_OFFSET;
  #ifdef SINGLE_MERGEDCORES_SET
  n_sets_to_find = 1*CORE_SPLIT_FACTOR;
  next_set_id += SETS_PER_IN_PAGE_OFFSET - n_sets_to_find;
  for (int i=0; i<NPAGES; i++) {
    struct cacheline *line = cachelines + i * LINES_PER_PAGE + IN_PAGE_CACHELINE_IDX;
    unsigned long paddr = get_physaddr((unsigned long)line);
    unsigned long set_mergedcore = (paddr / PAGE_SIZE) & (SETS_PER_IN_PAGE_OFFSET_MERGEDCORES-1);
    if (/*set_mergedcore != 0x0 && set_mergedcore != 0x10 && set_mergedcore != 0x8 &&*/ set_mergedcore != 0xa) {
      line->set_id = 1;
    }
  }
  #endif

  for (int i=0; i<n_sets_to_find; i++) {
    find_new_set();
    if (last_success_time != 0 && last_success_time + 60*5 < time(NULL)) {
      printf("%s giving up\n", cur_time());
      break;
    }
  }

  printf("%s remaining cachelines (not detected while scanning for other cachelines in sets): %d\n",
          cur_time(), count_unsorted_lines());

  //dump_all();

  //printf("%lf\n", binomial_probability_not_range(0, 20, 2150, 1/(double)192));
}
